import os
import streamlit as st

try:
    import google.generativeai as genai
except ImportError:
    st.error("google-generativeai íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”: pip install -U google-generativeai")
    st.stop()

# Configuration
MODEL_ID = "gemini-2.0-flash-exp"  # Try 2.0 exp first, fallback to 1.5 if not available

st.set_page_config(page_title="Gemini Chat Â· Streamlit", page_icon="ğŸ’¬", layout="centered")

# Read API key priority: Streamlit secrets -> environment -> text input
default_api_key = (
    st.secrets.get("GOOGLE_API_KEY", None)
    if hasattr(st, "secrets")
    else None
) or os.getenv("GOOGLE_API_KEY", "")

st.title("Gemini Chat Â· Streamlit")
st.caption("Google Generative AI SDKë¥¼ ì‚¬ìš©í•˜ì—¬ Gemini ëª¨ë¸ì„ í˜¸ì¶œí•©ë‹ˆë‹¤.")

with st.expander("API í‚¤ ì„¤ì •", expanded=not bool(default_api_key)):
    api_key = st.text_input(
        "Google API Key",
        type="password",
        value=default_api_key,
        help="í™˜ê²½ë³€ìˆ˜ GOOGLE_API_KEY ë˜ëŠ” Streamlit Secretsì—ë„ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
    )

active_api_key = api_key or default_api_key

if "messages" not in st.session_state:
    st.session_state.messages = []

def add_message(role: str, content: str):
    st.session_state.messages.append({"role": role, "content": content})


def call_gemini(prompt: str, api_key: str, model_name: str = MODEL_ID) -> str:
    if not api_key:
        raise ValueError("API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel(model_name)
        response = model.generate_content(
            prompt,
            generation_config=genai.types.GenerationConfig(temperature=0.7)
        )
        if not response.text:
            raise RuntimeError("ì‘ë‹µì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return response.text
    except Exception as e:
        error_msg = str(e)
        # Try fallback model if 2.0 is not available
        if "not found" in error_msg.lower() and model_name == MODEL_ID:
            st.warning(f"{model_name} ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. gemini-1.5-flashë¡œ ì¬ì‹œë„í•©ë‹ˆë‹¤...")
            return call_gemini(prompt, api_key, "gemini-1.5-flash")
        raise RuntimeError(f"API ì˜¤ë¥˜: {error_msg}")


st.subheader("ì—°ê²° ìƒíƒœ í™•ì¸", divider="gray")
col_test, col_hint = st.columns([1, 2])
with col_test:
    test_btn = st.button("ì—°ê²° í…ŒìŠ¤íŠ¸", use_container_width=True)
with col_hint:
    st.caption("ì§§ì€ ping í˜¸ì¶œë¡œ API ì—°ê²°ì„ í™•ì¸í•©ë‹ˆë‹¤.")

if test_btn:
    try:
        with st.spinner("í…ŒìŠ¤íŠ¸ í˜¸ì¶œ ì¤‘..."):
            _ = call_gemini("ping", active_api_key)
        st.success("API ì—°ê²° ì„±ê³µ")
    except Exception as e:  # noqa: BLE001
        st.error(f"API ì—°ê²° ì‹¤íŒ¨: {e}")

# Model selection
with st.expander("ëª¨ë¸ ì„ íƒ", expanded=False):
    model_option = st.selectbox(
        "ì‚¬ìš©í•  ëª¨ë¸",
        ["gemini-2.0-flash-exp", "gemini-1.5-flash", "gemini-1.5-pro"],
        help="gemini-2.0-flash-expë¥¼ ë¨¼ì € ì‹œë„í•˜ê³ , ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ gemini-1.5-flashë¡œ ëŒ€ì²´ë©ë‹ˆë‹¤."
    )

st.subheader("ì±„íŒ…", divider="gray")
with st.form("chat_form", clear_on_submit=True):
    prompt = st.text_area("ë©”ì‹œì§€", height=140, placeholder="ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”...")
    submitted = st.form_submit_button("Send")

if submitted and prompt.strip():
    add_message("user", prompt)
    try:
        with st.spinner("Gemini í˜¸ì¶œ ì¤‘..."):
            reply = call_gemini(prompt, active_api_key, model_option)
        add_message("assistant", reply)
    except Exception as e:  # noqa: BLE001
        st.error(str(e))

# Render chat history
for msg in st.session_state.messages:
    st.chat_message("assistant" if msg["role"] != "user" else "user").write(msg["content"])

st.caption("API í‚¤ëŠ” í´ë¼ì´ì–¸íŠ¸ì—ì„œë§Œ ì‚¬ìš©ë˜ë©° ì„œë²„ì— ì €ì¥ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

